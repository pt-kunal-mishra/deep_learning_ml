{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[\n",
    "    \"I love machine learning\",\n",
    "    \"I love deep learning\",\n",
    "    \"Natural language processing is fascinating\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=[sentences.lower().split() for sentences in sentences]\n",
    "token_flat=[word for sentences in tokens for word in sentences]\n",
    "\n",
    "\n",
    "vocab=Counter(token_flat)\n",
    "vocab_size=len(vocab)\n",
    "word2dix={word:i for i,(word,_)in enumerate(vocab.items())}\n",
    "idx2word={i:word for word,i in word2dix.items()}\n",
    "\n",
    "window_size = 2\n",
    "training_pairs = []\n",
    "\n",
    "for sentence in tokens:\n",
    "    for i, word in enumerate(sentence):\n",
    "        target = word2dix[word]\n",
    "        # Context words within the window size\n",
    "        context_words = sentence[max(0, i - window_size): i] + sentence[i + 1: min(len(sentence), i + window_size + 1)]\n",
    "        for context in context_words:\n",
    "            training_pairs.append((target, word2dix[context]))\n",
    "\n",
    "# Convert to tensor\n",
    "train_data = torch.LongTensor(training_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "class Word2VecSkipGram(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_dim):\n",
    "        super(Word2VecSkipGram,self).__init__()\n",
    "        self.embeddings=nn.Embedding(vocab_size,embedding_dim)\n",
    "    def forward(self,target):\n",
    "        return self.embeddings(target)\n",
    "\n",
    "embedding_dim=100\n",
    "model=Word2VecSkipGram(vocab_size,embedding_dim)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.1240388225106632\n",
      "Epoch 2, Loss: 1.1240378513055689\n",
      "Epoch 3, Loss: 1.1240368204958298\n",
      "Epoch 4, Loss: 1.124035870327669\n",
      "Epoch 5, Loss: 1.124034888604108\n",
      "Epoch 6, Loss: 1.1240339279174805\n",
      "Epoch 7, Loss: 1.1240329882677864\n",
      "Epoch 8, Loss: 1.124032010050381\n",
      "Epoch 9, Loss: 1.1240310143021977\n",
      "Epoch 10, Loss: 1.1240300150478588\n",
      "Epoch 11, Loss: 1.1240290508550757\n",
      "Epoch 12, Loss: 1.1240280849092148\n",
      "Epoch 13, Loss: 1.1240271364941317\n",
      "Epoch 14, Loss: 1.1240261372397928\n",
      "Epoch 15, Loss: 1.124025187071632\n",
      "Epoch 16, Loss: 1.1240242158665377\n",
      "Epoch 17, Loss: 1.1240232464145212\n",
      "Epoch 18, Loss: 1.1240222734563492\n",
      "Epoch 19, Loss: 1.1240213197820328\n",
      "Epoch 20, Loss: 1.1240203590954052\n",
      "Epoch 21, Loss: 1.1240193878903109\n",
      "Epoch 22, Loss: 1.124018455252928\n",
      "Epoch 23, Loss: 1.1240175015786116\n",
      "Epoch 24, Loss: 1.1240165198550505\n",
      "Epoch 25, Loss: 1.1240155644276564\n",
      "Epoch 26, Loss: 1.124014559914084\n",
      "Epoch 27, Loss: 1.12401365181979\n",
      "Epoch 28, Loss: 1.1240126490592957\n",
      "Epoch 29, Loss: 1.1240116953849792\n",
      "Epoch 30, Loss: 1.124010731192196\n",
      "Epoch 31, Loss: 1.124009775764802\n",
      "Epoch 32, Loss: 1.1240088448804968\n",
      "Epoch 33, Loss: 1.124007861403858\n",
      "Epoch 34, Loss: 1.124006920001086\n",
      "Epoch 35, Loss: 1.1240059417836807\n",
      "Epoch 36, Loss: 1.1240049810970532\n",
      "Epoch 37, Loss: 1.12400401690427\n",
      "Epoch 38, Loss: 1.12400304219302\n",
      "Epoch 39, Loss: 1.124002102543326\n",
      "Epoch 40, Loss: 1.124001127832076\n",
      "Epoch 41, Loss: 1.1240001864293043\n",
      "Epoch 42, Loss: 1.1239992555449991\n",
      "Epoch 43, Loss: 1.12399825629066\n",
      "Epoch 44, Loss: 1.1239973201471216\n",
      "Epoch 45, Loss: 1.123996359460494\n",
      "Epoch 46, Loss: 1.1239954057861776\n",
      "Epoch 47, Loss: 1.1239944486057056\n",
      "Epoch 48, Loss: 1.123993487919078\n",
      "Epoch 49, Loss: 1.1239925026893616\n",
      "Epoch 50, Loss: 1.1239915770642899\n",
      "Epoch 51, Loss: 1.1239906233899735\n",
      "Epoch 52, Loss: 1.1239896627033459\n",
      "Epoch 53, Loss: 1.1239886634490068\n",
      "Epoch 54, Loss: 1.1239877395770128\n",
      "Epoch 55, Loss: 1.1239867771373075\n",
      "Epoch 56, Loss: 1.123985798919902\n",
      "Epoch 57, Loss: 1.1239848399863523\n",
      "Epoch 58, Loss: 1.1239839231266695\n",
      "Epoch 59, Loss: 1.1239829484154196\n",
      "Epoch 60, Loss: 1.1239819596795475\n",
      "Epoch 61, Loss: 1.1239810200298535\n",
      "Epoch 62, Loss: 1.1239800383062923\n",
      "Epoch 63, Loss: 1.123979060088887\n",
      "Epoch 64, Loss: 1.1239781064145706\n",
      "Epoch 65, Loss: 1.123977170271032\n",
      "Epoch 66, Loss: 1.1239762271151823\n",
      "Epoch 67, Loss: 1.1239752524039324\n",
      "Epoch 68, Loss: 1.123974267174216\n",
      "Epoch 69, Loss: 1.1239732889568104\n",
      "Epoch 70, Loss: 1.1239723826155943\n",
      "Epoch 71, Loss: 1.1239714342005112\n",
      "Epoch 72, Loss: 1.1239704857854282\n",
      "Epoch 73, Loss: 1.1239695426295786\n",
      "Epoch 74, Loss: 1.1239685626590954\n",
      "Epoch 75, Loss: 1.1239676335278679\n",
      "Epoch 76, Loss: 1.1239666623227738\n",
      "Epoch 77, Loss: 1.1239657016361462\n",
      "Epoch 78, Loss: 1.123964761986452\n",
      "Epoch 79, Loss: 1.1239638188306023\n",
      "Epoch 80, Loss: 1.123962840613197\n",
      "Epoch 81, Loss: 1.1239619114819694\n",
      "Epoch 82, Loss: 1.1239610139061422\n",
      "Epoch 83, Loss: 1.1239600269233478\n",
      "Epoch 84, Loss: 1.1239590925328873\n",
      "Epoch 85, Loss: 1.123958152883193\n",
      "Epoch 86, Loss: 1.123957179925021\n",
      "Epoch 87, Loss: 1.1239562350160934\n",
      "Epoch 88, Loss: 1.1239552918602438\n",
      "Epoch 89, Loss: 1.1239543206551497\n",
      "Epoch 90, Loss: 1.1239533774992998\n",
      "Epoch 91, Loss: 1.123952427331139\n",
      "Epoch 92, Loss: 1.1239514526198893\n",
      "Epoch 93, Loss: 1.1239505164763506\n",
      "Epoch 94, Loss: 1.1239495522835676\n",
      "Epoch 95, Loss: 1.1239485880907845\n",
      "Epoch 96, Loss: 1.123947683502646\n",
      "Epoch 97, Loss: 1.1239467315814073\n",
      "Epoch 98, Loss: 1.123945762129391\n",
      "Epoch 99, Loss: 1.123944829492008\n",
      "Epoch 100, Loss: 1.1239439143854029\n",
      "Epoch 101, Loss: 1.1239429291556864\n",
      "Epoch 102, Loss: 1.1239419930121477\n",
      "Epoch 103, Loss: 1.1239410305724424\n",
      "Epoch 104, Loss: 1.1239400891696705\n",
      "Epoch 105, Loss: 1.123939119717654\n",
      "Epoch 106, Loss: 1.1239381818210377\n",
      "Epoch 107, Loss: 1.1239372526898104\n",
      "Epoch 108, Loss: 1.1239362639539383\n",
      "Epoch 109, Loss: 1.1239353523534887\n",
      "Epoch 110, Loss: 1.1239343986791723\n",
      "Epoch 111, Loss: 1.1239334555233227\n",
      "Epoch 112, Loss: 1.123932519379784\n",
      "Epoch 113, Loss: 1.1239315849893234\n",
      "Epoch 114, Loss: 1.1239306190434624\n",
      "Epoch 115, Loss: 1.1239296197891235\n",
      "Epoch 116, Loss: 1.123928732731763\n",
      "Epoch 117, Loss: 1.1239277895759134\n",
      "Epoch 118, Loss: 1.1239268429139082\n",
      "Epoch 119, Loss: 1.1239258752149694\n",
      "Epoch 120, Loss: 1.1239249723799087\n",
      "Epoch 121, Loss: 1.1239240239648258\n",
      "Epoch 122, Loss: 1.1239230212043314\n",
      "Epoch 123, Loss: 1.1239220973323374\n",
      "Epoch 124, Loss: 1.1239211243741654\n",
      "Epoch 125, Loss: 1.123920219786027\n",
      "Epoch 126, Loss: 1.1239192643586327\n",
      "Epoch 127, Loss: 1.123918338733561\n",
      "Epoch 128, Loss: 1.123917379800011\n",
      "Epoch 129, Loss: 1.123916424372617\n",
      "Epoch 130, Loss: 1.123915500500623\n",
      "Epoch 131, Loss: 1.1239145503324621\n",
      "Epoch 132, Loss: 1.1239136141889237\n",
      "Epoch 133, Loss: 1.1239126675269182\n",
      "Epoch 134, Loss: 1.1239117401487686\n",
      "Epoch 135, Loss: 1.1239107777090633\n",
      "Epoch 136, Loss: 1.1239098187755137\n",
      "Epoch 137, Loss: 1.123908891397364\n",
      "Epoch 138, Loss: 1.123907958759981\n",
      "Epoch 139, Loss: 1.1239070401472204\n",
      "Epoch 140, Loss: 1.1239061250406153\n",
      "Epoch 141, Loss: 1.1239051590947544\n",
      "Epoch 142, Loss: 1.1239042106796713\n",
      "Epoch 143, Loss: 1.1239032517461216\n",
      "Epoch 144, Loss: 1.1239023103433496\n",
      "Epoch 145, Loss: 1.1239013952367447\n",
      "Epoch 146, Loss: 1.1239004345501171\n",
      "Epoch 147, Loss: 1.1238995089250452\n",
      "Epoch 148, Loss: 1.1238985587568844\n",
      "Epoch 149, Loss: 1.1238976348848904\n",
      "Epoch 150, Loss: 1.1238966917290407\n",
      "Epoch 151, Loss: 1.1238957643508911\n",
      "Epoch 152, Loss: 1.1238948141827303\n",
      "Epoch 153, Loss: 1.1238938219407026\n",
      "Epoch 154, Loss: 1.123892910340253\n",
      "Epoch 155, Loss: 1.12389196192517\n",
      "Epoch 156, Loss: 1.1238910029916203\n",
      "Epoch 157, Loss: 1.1238901019096375\n",
      "Epoch 158, Loss: 1.1238891552476322\n",
      "Epoch 159, Loss: 1.1238882015733158\n",
      "Epoch 160, Loss: 1.1238873145159554\n",
      "Epoch 161, Loss: 1.1238863818785723\n",
      "Epoch 162, Loss: 1.1238854176857893\n",
      "Epoch 163, Loss: 1.1238844745299394\n",
      "Epoch 164, Loss: 1.12388356292949\n",
      "Epoch 165, Loss: 1.1238826162674849\n",
      "Epoch 166, Loss: 1.1238816836301018\n",
      "Epoch 167, Loss: 1.1238807755358078\n",
      "Epoch 168, Loss: 1.1238798078368692\n",
      "Epoch 169, Loss: 1.123878876952564\n",
      "Epoch 170, Loss: 1.12387798463597\n",
      "Epoch 171, Loss: 1.1238770414801205\n",
      "Epoch 172, Loss: 1.1238761509166044\n",
      "Epoch 173, Loss: 1.123875172699199\n",
      "Epoch 174, Loss: 1.1238742435679716\n",
      "Epoch 175, Loss: 1.1238732969059664\n",
      "Epoch 176, Loss: 1.1238723712808945\n",
      "Epoch 177, Loss: 1.1238714316312004\n",
      "Epoch 178, Loss: 1.1238705060061287\n",
      "Epoch 179, Loss: 1.123869562850279\n",
      "Epoch 180, Loss: 1.123868638978285\n",
      "Epoch 181, Loss: 1.123867697575513\n",
      "Epoch 182, Loss: 1.1238667684442856\n",
      "Epoch 183, Loss: 1.1238658305476694\n",
      "Epoch 184, Loss: 1.123864892651053\n",
      "Epoch 185, Loss: 1.123863984556759\n",
      "Epoch 186, Loss: 1.1238630343885982\n",
      "Epoch 187, Loss: 1.1238621017512154\n",
      "Epoch 188, Loss: 1.1238611936569214\n",
      "Epoch 189, Loss: 1.123860264525694\n",
      "Epoch 190, Loss: 1.1238592880613663\n",
      "Epoch 191, Loss: 1.1238583939916946\n",
      "Epoch 192, Loss: 1.1238574666135452\n",
      "Epoch 193, Loss: 1.1238565409884733\n",
      "Epoch 194, Loss: 1.1238555978326237\n",
      "Epoch 195, Loss: 1.1238546722075518\n",
      "Epoch 196, Loss: 1.1238537676194136\n",
      "Epoch 197, Loss: 1.1238528016735525\n",
      "Epoch 198, Loss: 1.1238518848138697\n",
      "Epoch 199, Loss: 1.1238509626949535\n",
      "Epoch 200, Loss: 1.1238500195391037\n",
      "Epoch 201, Loss: 1.123849118457121\n",
      "Epoch 202, Loss: 1.1238481647828047\n",
      "Epoch 203, Loss: 1.1238472601946663\n",
      "Epoch 204, Loss: 1.1238463310634388\n",
      "Epoch 205, Loss: 1.1238453966729782\n",
      "Epoch 206, Loss: 1.1238444692948286\n",
      "Epoch 207, Loss: 1.1238435506820679\n",
      "Epoch 208, Loss: 1.1238426320693071\n",
      "Epoch 209, Loss: 1.123841727481169\n",
      "Epoch 210, Loss: 1.1238408263991861\n",
      "Epoch 211, Loss: 1.123839879737181\n",
      "Epoch 212, Loss: 1.123838936581331\n",
      "Epoch 213, Loss: 1.1238380179685705\n",
      "Epoch 214, Loss: 1.123837088837343\n",
      "Epoch 215, Loss: 1.1238361526938045\n",
      "Epoch 216, Loss: 1.123835249858744\n",
      "Epoch 217, Loss: 1.12383432598675\n",
      "Epoch 218, Loss: 1.1238333793247448\n",
      "Epoch 219, Loss: 1.1238324536996729\n",
      "Epoch 220, Loss: 1.123831538593068\n",
      "Epoch 221, Loss: 1.1238306199803072\n",
      "Epoch 222, Loss: 1.1238297083798576\n",
      "Epoch 223, Loss: 1.1238287862609415\n",
      "Epoch 224, Loss: 1.1238278764135696\n",
      "Epoch 225, Loss: 1.1238269157269423\n",
      "Epoch 226, Loss: 1.123825993608026\n",
      "Epoch 227, Loss: 1.1238250732421875\n",
      "Epoch 228, Loss: 1.1238241511232712\n",
      "Epoch 229, Loss: 1.123823229004355\n",
      "Epoch 230, Loss: 1.1238223068854387\n",
      "Epoch 231, Loss: 1.1238213724949782\n",
      "Epoch 232, Loss: 1.1238204661537619\n",
      "Epoch 233, Loss: 1.123819531763301\n",
      "Epoch 234, Loss: 1.123818649965174\n",
      "Epoch 235, Loss: 1.1238176472046797\n",
      "Epoch 236, Loss: 1.123816761900397\n",
      "Epoch 237, Loss: 1.1238158590653364\n",
      "Epoch 238, Loss: 1.1238149351933424\n",
      "Epoch 239, Loss: 1.1238140113213484\n",
      "Epoch 240, Loss: 1.12381310673321\n",
      "Epoch 241, Loss: 1.1238121635773604\n",
      "Epoch 242, Loss: 1.1238112554830664\n",
      "Epoch 243, Loss: 1.1238103158333723\n",
      "Epoch 244, Loss: 1.123809376183678\n",
      "Epoch 245, Loss: 1.123808452311684\n",
      "Epoch 246, Loss: 1.12380752843969\n",
      "Epoch 247, Loss: 1.1238065993084627\n",
      "Epoch 248, Loss: 1.1238056771895464\n",
      "Epoch 249, Loss: 1.1238047585767859\n",
      "Epoch 250, Loss: 1.1238038434701807\n",
      "Epoch 251, Loss: 1.1238029458943535\n",
      "Epoch 252, Loss: 1.1238019904669594\n",
      "Epoch 253, Loss: 1.1238010981503654\n",
      "Epoch 254, Loss: 1.123800162006827\n",
      "Epoch 255, Loss: 1.1237992591717665\n",
      "Epoch 256, Loss: 1.1237983563367058\n",
      "Epoch 257, Loss: 1.1237974692793453\n",
      "Epoch 258, Loss: 1.1237965120988733\n",
      "Epoch 259, Loss: 1.1237955759553349\n",
      "Epoch 260, Loss: 1.1237947029225968\n",
      "Epoch 261, Loss: 1.1237937808036804\n",
      "Epoch 262, Loss: 1.123792858684764\n",
      "Epoch 263, Loss: 1.123791968121248\n",
      "Epoch 264, Loss: 1.123791046002332\n",
      "Epoch 265, Loss: 1.1237901273895712\n",
      "Epoch 266, Loss: 1.1237892578629887\n",
      "Epoch 267, Loss: 1.12378829016405\n",
      "Epoch 268, Loss: 1.1237873470082003\n",
      "Epoch 269, Loss: 1.1237864424200619\n",
      "Epoch 270, Loss: 1.1237855378319235\n",
      "Epoch 271, Loss: 1.1237846402560963\n",
      "Epoch 272, Loss: 1.123783711124869\n",
      "Epoch 273, Loss: 1.1237828170551973\n",
      "Epoch 274, Loss: 1.123781870393192\n",
      "Epoch 275, Loss: 1.1237809938542984\n",
      "Epoch 276, Loss: 1.123780015636893\n",
      "Epoch 277, Loss: 1.1237791128018324\n",
      "Epoch 278, Loss: 1.1237782310037052\n",
      "Epoch 279, Loss: 1.1237773158971\n",
      "Epoch 280, Loss: 1.1237764113089617\n",
      "Epoch 281, Loss: 1.123775510226979\n",
      "Epoch 282, Loss: 1.123774577589596\n",
      "Epoch 283, Loss: 1.1237736659891464\n",
      "Epoch 284, Loss: 1.1237727017963635\n",
      "Epoch 285, Loss: 1.1237718182451584\n",
      "Epoch 286, Loss: 1.1237708961262423\n",
      "Epoch 287, Loss: 1.123769974007326\n",
      "Epoch 288, Loss: 1.123769058900721\n",
      "Epoch 289, Loss: 1.1237681753495161\n",
      "Epoch 290, Loss: 1.1237672321936663\n",
      "Epoch 291, Loss: 1.1237663135809057\n",
      "Epoch 292, Loss: 1.123765444054323\n",
      "Epoch 293, Loss: 1.123764462330762\n",
      "Epoch 294, Loss: 1.1237635594957016\n",
      "Epoch 295, Loss: 1.1237626531544853\n",
      "Epoch 296, Loss: 1.1237617170109468\n",
      "Epoch 297, Loss: 1.1237608229412752\n",
      "Epoch 298, Loss: 1.1237599218592924\n",
      "Epoch 299, Loss: 1.1237590225303875\n",
      "Epoch 300, Loss: 1.123758095152238\n",
      "Epoch 301, Loss: 1.1237571747863995\n",
      "Epoch 302, Loss: 1.1237562509144055\n",
      "Epoch 303, Loss: 1.1237553568447338\n",
      "Epoch 304, Loss: 1.1237544522565954\n",
      "Epoch 305, Loss: 1.1237535546807682\n",
      "Epoch 306, Loss: 1.1237526097718407\n",
      "Epoch 307, Loss: 1.1237517069367802\n",
      "Epoch 308, Loss: 1.1237508111140306\n",
      "Epoch 309, Loss: 1.123749869711259\n",
      "Epoch 310, Loss: 1.123749010703143\n",
      "Epoch 311, Loss: 1.12374807806576\n",
      "Epoch 312, Loss: 1.1237472050330217\n",
      "Epoch 313, Loss: 1.1237462688894833\n",
      "Epoch 314, Loss: 1.123745373066734\n",
      "Epoch 315, Loss: 1.1237444684785955\n",
      "Epoch 316, Loss: 1.1237435516189127\n",
      "Epoch 317, Loss: 1.123742633006152\n",
      "Epoch 318, Loss: 1.1237417284180136\n",
      "Epoch 319, Loss: 1.123740834348342\n",
      "Epoch 320, Loss: 1.1237398911924923\n",
      "Epoch 321, Loss: 1.123738995369743\n",
      "Epoch 322, Loss: 1.1237380837692934\n",
      "Epoch 323, Loss: 1.1237371984650106\n",
      "Epoch 324, Loss: 1.1237362833584057\n",
      "Epoch 325, Loss: 1.1237353682518005\n",
      "Epoch 326, Loss: 1.12373448119444\n",
      "Epoch 327, Loss: 1.1237335976432352\n",
      "Epoch 328, Loss: 1.1237326860427856\n",
      "Epoch 329, Loss: 1.123731741133858\n",
      "Epoch 330, Loss: 1.1237308418049532\n",
      "Epoch 331, Loss: 1.123729926698348\n",
      "Epoch 332, Loss: 1.1237290431471432\n",
      "Epoch 333, Loss: 1.1237281420651604\n",
      "Epoch 334, Loss: 1.1237272234523998\n",
      "Epoch 335, Loss: 1.1237263504196615\n",
      "Epoch 336, Loss: 1.1237254423253678\n",
      "Epoch 337, Loss: 1.1237245798110962\n",
      "Epoch 338, Loss: 1.1237236471737133\n",
      "Epoch 339, Loss: 1.1237227180424858\n",
      "Epoch 340, Loss: 1.1237218064420365\n",
      "Epoch 341, Loss: 1.1237209088662092\n",
      "Epoch 342, Loss: 1.1237199972657597\n",
      "Epoch 343, Loss: 1.1237191102083992\n",
      "Epoch 344, Loss: 1.1237181898425608\n",
      "Epoch 345, Loss: 1.1237173150567448\n",
      "Epoch 346, Loss: 1.1237163543701172\n",
      "Epoch 347, Loss: 1.1237154848435347\n",
      "Epoch 348, Loss: 1.123714597786174\n",
      "Epoch 349, Loss: 1.123713700210347\n",
      "Epoch 350, Loss: 1.1237127360175638\n",
      "Epoch 351, Loss: 1.123711819157881\n",
      "Epoch 352, Loss: 1.1237109478782206\n",
      "Epoch 353, Loss: 1.1237100923762602\n",
      "Epoch 354, Loss: 1.1237091912942774\n",
      "Epoch 355, Loss: 1.123708304236917\n",
      "Epoch 356, Loss: 1.1237074136734009\n",
      "Epoch 357, Loss: 1.1237065020729513\n",
      "Epoch 358, Loss: 1.1237055992378908\n",
      "Epoch 359, Loss: 1.1237046841312857\n",
      "Epoch 360, Loss: 1.1237037497408249\n",
      "Epoch 361, Loss: 1.1237028977450203\n",
      "Epoch 362, Loss: 1.1237020141938154\n",
      "Epoch 363, Loss: 1.123701092074899\n",
      "Epoch 364, Loss: 1.1237002085236942\n",
      "Epoch 365, Loss: 1.1236993232194115\n",
      "Epoch 366, Loss: 1.123698404606651\n",
      "Epoch 367, Loss: 1.1236975333269905\n",
      "Epoch 368, Loss: 1.1236966357511633\n",
      "Epoch 369, Loss: 1.123695704866858\n",
      "Epoch 370, Loss: 1.1236948055379532\n",
      "Epoch 371, Loss: 1.1236938869251925\n",
      "Epoch 372, Loss: 1.1236929875962876\n",
      "Epoch 373, Loss: 1.1236920952796936\n",
      "Epoch 374, Loss: 1.1236911994569443\n",
      "Epoch 375, Loss: 1.1236903667449951\n",
      "Epoch 376, Loss: 1.1236894726753235\n",
      "Epoch 377, Loss: 1.1236885505564072\n",
      "Epoch 378, Loss: 1.1236876564867355\n",
      "Epoch 379, Loss: 1.1236867413801306\n",
      "Epoch 380, Loss: 1.1236858683473923\n",
      "Epoch 381, Loss: 1.1236850005738876\n",
      "Epoch 382, Loss: 1.1236841257880716\n",
      "Epoch 383, Loss: 1.123683189644533\n",
      "Epoch 384, Loss: 1.1236822920687057\n",
      "Epoch 385, Loss: 1.1236814225421232\n",
      "Epoch 386, Loss: 1.1236805354847628\n",
      "Epoch 387, Loss: 1.1236796361558579\n",
      "Epoch 388, Loss: 1.1236787192961748\n",
      "Epoch 389, Loss: 1.1236778550288256\n",
      "Epoch 390, Loss: 1.1236769556999207\n",
      "Epoch 391, Loss: 1.1236760598771713\n",
      "Epoch 392, Loss: 1.123675121980555\n",
      "Epoch 393, Loss: 1.1236742261578054\n",
      "Epoch 394, Loss: 1.123673388186623\n",
      "Epoch 395, Loss: 1.1236724678207846\n",
      "Epoch 396, Loss: 1.1236716280965244\n",
      "Epoch 397, Loss: 1.1236707200022304\n",
      "Epoch 398, Loss: 1.1236698452164144\n",
      "Epoch 399, Loss: 1.123668891542098\n",
      "Epoch 400, Loss: 1.12366801850936\n",
      "Epoch 401, Loss: 1.123667127945844\n",
      "Epoch 402, Loss: 1.1236662303700167\n",
      "Epoch 403, Loss: 1.1236653468188118\n",
      "Epoch 404, Loss: 1.1236644755391514\n",
      "Epoch 405, Loss: 1.1236635762102463\n",
      "Epoch 406, Loss: 1.1236626681159525\n",
      "Epoch 407, Loss: 1.1236617915770586\n",
      "Epoch 408, Loss: 1.123660890495076\n",
      "Epoch 409, Loss: 1.1236599946723265\n",
      "Epoch 410, Loss: 1.1236591023557327\n",
      "Epoch 411, Loss: 1.1236582223106832\n",
      "Epoch 412, Loss: 1.123657333500245\n",
      "Epoch 413, Loss: 1.123656476245207\n",
      "Epoch 414, Loss: 1.1236555751632242\n",
      "Epoch 415, Loss: 1.1236546810935526\n",
      "Epoch 416, Loss: 1.1236537922831142\n",
      "Epoch 417, Loss: 1.1236528859418982\n",
      "Epoch 418, Loss: 1.1236520304399378\n",
      "Epoch 419, Loss: 1.123651138123344\n",
      "Epoch 420, Loss: 1.1236502265228945\n",
      "Epoch 421, Loss: 1.1236493517370785\n",
      "Epoch 422, Loss: 1.1236484436427845\n",
      "Epoch 423, Loss: 1.1236475600915796\n",
      "Epoch 424, Loss: 1.1236466519972856\n",
      "Epoch 425, Loss: 1.1236457719522364\n",
      "Epoch 426, Loss: 1.1236449041787315\n",
      "Epoch 427, Loss: 1.1236440066029043\n",
      "Epoch 428, Loss: 1.123643102014766\n",
      "Epoch 429, Loss: 1.1236422412535723\n",
      "Epoch 430, Loss: 1.1236413682208342\n",
      "Epoch 431, Loss: 1.1236404408426846\n",
      "Epoch 432, Loss: 1.1236395555384018\n",
      "Epoch 433, Loss: 1.123638696530286\n",
      "Epoch 434, Loss: 1.1236377603867476\n",
      "Epoch 435, Loss: 1.1236368961193983\n",
      "Epoch 436, Loss: 1.1236359932843376\n",
      "Epoch 437, Loss: 1.1236351097331327\n",
      "Epoch 438, Loss: 1.1236342402065502\n",
      "Epoch 439, Loss: 1.1236333636676563\n",
      "Epoch 440, Loss: 1.1236324748572182\n",
      "Epoch 441, Loss: 1.1236315790344686\n",
      "Epoch 442, Loss: 1.1236306954832638\n",
      "Epoch 443, Loss: 1.123629810178981\n",
      "Epoch 444, Loss: 1.1236289178623873\n",
      "Epoch 445, Loss: 1.1236280343111824\n",
      "Epoch 446, Loss: 1.1236271893276888\n",
      "Epoch 447, Loss: 1.1236262777272392\n",
      "Epoch 448, Loss: 1.1236254046945011\n",
      "Epoch 449, Loss: 1.1236244860817404\n",
      "Epoch 450, Loss: 1.1236236358390135\n",
      "Epoch 451, Loss: 1.1236227698185866\n",
      "Epoch 452, Loss: 1.1236218775019926\n",
      "Epoch 453, Loss: 1.1236210307654213\n",
      "Epoch 454, Loss: 1.123620141954983\n",
      "Epoch 455, Loss: 1.123619258403778\n",
      "Epoch 456, Loss: 1.1236183468033285\n",
      "Epoch 457, Loss: 1.1236174562398125\n",
      "Epoch 458, Loss: 1.123616553404752\n",
      "Epoch 459, Loss: 1.123615662841236\n",
      "Epoch 460, Loss: 1.1236147635123308\n",
      "Epoch 461, Loss: 1.1236139080103706\n",
      "Epoch 462, Loss: 1.1236130209530102\n",
      "Epoch 463, Loss: 1.123612172463361\n",
      "Epoch 464, Loss: 1.1236112538506002\n",
      "Epoch 465, Loss: 1.1236103422501509\n",
      "Epoch 466, Loss: 1.1236094849951126\n",
      "Epoch 467, Loss: 1.1236086102092968\n",
      "Epoch 468, Loss: 1.1236077354234808\n",
      "Epoch 469, Loss: 1.1236068536253536\n",
      "Epoch 470, Loss: 1.123605928000282\n",
      "Epoch 471, Loss: 1.1236050830167883\n",
      "Epoch 472, Loss: 1.1236042310209835\n",
      "Epoch 473, Loss: 1.1236033404574675\n",
      "Epoch 474, Loss: 1.1236024726839626\n",
      "Epoch 475, Loss: 1.123601578614291\n",
      "Epoch 476, Loss: 1.1236006827915417\n",
      "Epoch 477, Loss: 1.1235997992403366\n",
      "Epoch 478, Loss: 1.1235989121829761\n",
      "Epoch 479, Loss: 1.1235980496687048\n",
      "Epoch 480, Loss: 1.1235971591051888\n",
      "Epoch 481, Loss: 1.1235962930847616\n",
      "Epoch 482, Loss: 1.1235954042743235\n",
      "Epoch 483, Loss: 1.1235944979331072\n",
      "Epoch 484, Loss: 1.123593673986547\n",
      "Epoch 485, Loss: 1.1235928044599646\n",
      "Epoch 486, Loss: 1.1235918963656706\n",
      "Epoch 487, Loss: 1.1235910128144657\n",
      "Epoch 488, Loss: 1.1235901397817276\n",
      "Epoch 489, Loss: 1.1235892737613005\n",
      "Epoch 490, Loss: 1.1235883989754845\n",
      "Epoch 491, Loss: 1.1235875101650463\n",
      "Epoch 492, Loss: 1.1235866406384636\n",
      "Epoch 493, Loss: 1.1235857746180367\n",
      "Epoch 494, Loss: 1.1235848840545206\n",
      "Epoch 495, Loss: 1.1235840145279379\n",
      "Epoch 496, Loss: 1.1235831344828886\n",
      "Epoch 497, Loss: 1.1235823017709397\n",
      "Epoch 498, Loss: 1.123581423478968\n",
      "Epoch 499, Loss: 1.1235805504462297\n",
      "Epoch 500, Loss: 1.1235796949442696\n",
      "Epoch 501, Loss: 1.1235787868499756\n",
      "Epoch 502, Loss: 1.1235779278418596\n",
      "Epoch 503, Loss: 1.123577033772188\n",
      "Epoch 504, Loss: 1.123576185282539\n",
      "Epoch 505, Loss: 1.123575310496723\n",
      "Epoch 506, Loss: 1.1235744164270514\n",
      "Epoch 507, Loss: 1.1235735626781689\n",
      "Epoch 508, Loss: 1.1235726826331194\n",
      "Epoch 509, Loss: 1.1235718078473036\n",
      "Epoch 510, Loss: 1.1235709435799544\n",
      "Epoch 511, Loss: 1.1235700460041271\n",
      "Epoch 512, Loss: 1.1235691589467667\n",
      "Epoch 513, Loss: 1.1235683367532843\n",
      "Epoch 514, Loss: 1.1235674987821018\n",
      "Epoch 515, Loss: 1.1235666064655079\n",
      "Epoch 516, Loss: 1.123565722914303\n",
      "Epoch 517, Loss: 1.1235648533877205\n",
      "Epoch 518, Loss: 1.1235639978857601\n",
      "Epoch 519, Loss: 1.1235631301122553\n",
      "Epoch 520, Loss: 1.1235623254495508\n",
      "Epoch 521, Loss: 1.1235614068367903\n",
      "Epoch 522, Loss: 1.1235605232855852\n",
      "Epoch 523, Loss: 1.1235596818082474\n",
      "Epoch 524, Loss: 1.1235588157878202\n",
      "Epoch 525, Loss: 1.1235579427550821\n",
      "Epoch 526, Loss: 1.1235570977715885\n",
      "Epoch 527, Loss: 1.123556186171139\n",
      "Epoch 528, Loss: 1.1235553271630232\n",
      "Epoch 529, Loss: 1.1235544593895184\n",
      "Epoch 530, Loss: 1.1235535810975468\n",
      "Epoch 531, Loss: 1.123552753644831\n",
      "Epoch 532, Loss: 1.1235518245136036\n",
      "Epoch 533, Loss: 1.1235509619993322\n",
      "Epoch 534, Loss: 1.123550081954283\n",
      "Epoch 535, Loss: 1.1235492439831005\n",
      "Epoch 536, Loss: 1.12354837270344\n",
      "Epoch 537, Loss: 1.1235474996707018\n",
      "Epoch 538, Loss: 1.1235466143664192\n",
      "Epoch 539, Loss: 1.1235457588644588\n",
      "Epoch 540, Loss: 1.123544924399432\n",
      "Epoch 541, Loss: 1.1235440268236048\n",
      "Epoch 542, Loss: 1.1235431818401111\n",
      "Epoch 543, Loss: 1.1235423368566178\n",
      "Epoch 544, Loss: 1.1235414585646462\n",
      "Epoch 545, Loss: 1.1235405855319078\n",
      "Epoch 546, Loss: 1.1235397282768698\n",
      "Epoch 547, Loss: 1.1235388622564428\n",
      "Epoch 548, Loss: 1.1235380242852604\n",
      "Epoch 549, Loss: 1.1235371512525223\n",
      "Epoch 550, Loss: 1.123536246664384\n",
      "Epoch 551, Loss: 1.1235353736316456\n",
      "Epoch 552, Loss: 1.1235345391666187\n",
      "Epoch 553, Loss: 1.1235336819115807\n",
      "Epoch 554, Loss: 1.1235328316688538\n",
      "Epoch 555, Loss: 1.1235319340930265\n",
      "Epoch 556, Loss: 1.1235310926156885\n",
      "Epoch 557, Loss: 1.1235302406198837\n",
      "Epoch 558, Loss: 1.1235293745994568\n",
      "Epoch 559, Loss: 1.1235285261098076\n",
      "Epoch 560, Loss: 1.1235276495709139\n",
      "Epoch 561, Loss: 1.1235267870566423\n",
      "Epoch 562, Loss: 1.1235259280485266\n",
      "Epoch 563, Loss: 1.1235250304726994\n",
      "Epoch 564, Loss: 1.123524192501517\n",
      "Epoch 565, Loss: 1.1235233159626232\n",
      "Epoch 566, Loss: 1.1235224464360405\n",
      "Epoch 567, Loss: 1.1235216014525469\n",
      "Epoch 568, Loss: 1.1235207634813644\n",
      "Epoch 569, Loss: 1.1235198922017042\n",
      "Epoch 570, Loss: 1.123518994625877\n",
      "Epoch 571, Loss: 1.1235181619139278\n",
      "Epoch 572, Loss: 1.1235172993996565\n",
      "Epoch 573, Loss: 1.1235164123422958\n",
      "Epoch 574, Loss: 1.1235155603464912\n",
      "Epoch 575, Loss: 1.1235147241283865\n",
      "Epoch 576, Loss: 1.1235138668733484\n",
      "Epoch 577, Loss: 1.1235130008529215\n",
      "Epoch 578, Loss: 1.1235121523632723\n",
      "Epoch 579, Loss: 1.123511263552834\n",
      "Epoch 580, Loss: 1.1235103782485514\n",
      "Epoch 581, Loss: 1.1235095543019913\n",
      "Epoch 582, Loss: 1.123508698800031\n",
      "Epoch 583, Loss: 1.1235078520634596\n",
      "Epoch 584, Loss: 1.123506973771488\n",
      "Epoch 585, Loss: 1.1235060691833496\n",
      "Epoch 586, Loss: 1.1235052382244783\n",
      "Epoch 587, Loss: 1.1235043897348291\n",
      "Epoch 588, Loss: 1.123503534232869\n",
      "Epoch 589, Loss: 1.1235026471755083\n",
      "Epoch 590, Loss: 1.1235018232289482\n",
      "Epoch 591, Loss: 1.1235009291592766\n",
      "Epoch 592, Loss: 1.123500077163472\n",
      "Epoch 593, Loss: 1.123499218155356\n",
      "Epoch 594, Loss: 1.1234983538880068\n",
      "Epoch 595, Loss: 1.1234975001391243\n",
      "Epoch 596, Loss: 1.123496651649475\n",
      "Epoch 597, Loss: 1.1234958241967594\n",
      "Epoch 598, Loss: 1.1234949441517101\n",
      "Epoch 599, Loss: 1.123494095662061\n",
      "Epoch 600, Loss: 1.1234932331477894\n",
      "Epoch 601, Loss: 1.123492395176607\n",
      "Epoch 602, Loss: 1.1234915238969467\n",
      "Epoch 603, Loss: 1.1234906946911531\n",
      "Epoch 604, Loss: 1.1234898111399483\n",
      "Epoch 605, Loss: 1.1234889731687658\n",
      "Epoch 606, Loss: 1.123488087864483\n",
      "Epoch 607, Loss: 1.1234872621648453\n",
      "Epoch 608, Loss: 1.1234863786136402\n",
      "Epoch 609, Loss: 1.1234855160993689\n",
      "Epoch 610, Loss: 1.123484681634342\n",
      "Epoch 611, Loss: 1.1234838436631596\n",
      "Epoch 612, Loss: 1.1234829636181103\n",
      "Epoch 613, Loss: 1.1234820730545942\n",
      "Epoch 614, Loss: 1.1234812368364895\n",
      "Epoch 615, Loss: 1.1234804041245405\n",
      "Epoch 616, Loss: 1.1234794960302465\n",
      "Epoch 617, Loss: 1.123478682602153\n",
      "Epoch 618, Loss: 1.1234778060632593\n",
      "Epoch 619, Loss: 1.1234769540674545\n",
      "Epoch 620, Loss: 1.1234761160962723\n",
      "Epoch 621, Loss: 1.1234752465696896\n",
      "Epoch 622, Loss: 1.1234744208700516\n",
      "Epoch 623, Loss: 1.1234735566027023\n",
      "Epoch 624, Loss: 1.1234727081130533\n",
      "Epoch 625, Loss: 1.1234718841664932\n",
      "Epoch 626, Loss: 1.1234709971091326\n",
      "Epoch 627, Loss: 1.123470136347939\n",
      "Epoch 628, Loss: 1.1234692966236788\n",
      "Epoch 629, Loss: 1.123468428850174\n",
      "Epoch 630, Loss: 1.1234676013974583\n",
      "Epoch 631, Loss: 1.1234667160931755\n",
      "Epoch 632, Loss: 1.1234658816281486\n",
      "Epoch 633, Loss: 1.1234650156077217\n",
      "Epoch 634, Loss: 1.1234641565996057\n",
      "Epoch 635, Loss: 1.1234633028507233\n",
      "Epoch 636, Loss: 1.1234624280649073\n",
      "Epoch 637, Loss: 1.1234615865875692\n",
      "Epoch 638, Loss: 1.1234607486163868\n",
      "Epoch 639, Loss: 1.1234599036328934\n",
      "Epoch 640, Loss: 1.1234590691678665\n",
      "Epoch 641, Loss: 1.1234582171720617\n",
      "Epoch 642, Loss: 1.1234574247809017\n",
      "Epoch 643, Loss: 1.1234565517481636\n",
      "Epoch 644, Loss: 1.1234556752092697\n",
      "Epoch 645, Loss: 1.1234548302257763\n",
      "Epoch 646, Loss: 1.123454023809994\n",
      "Epoch 647, Loss: 1.123453182332656\n",
      "Epoch 648, Loss: 1.1234522882629843\n",
      "Epoch 649, Loss: 1.1234514853533577\n",
      "Epoch 650, Loss: 1.1234506123206194\n",
      "Epoch 651, Loss: 1.1234497813617481\n",
      "Epoch 652, Loss: 1.1234488890451544\n",
      "Epoch 653, Loss: 1.1234480738639832\n",
      "Epoch 654, Loss: 1.1234471938189339\n",
      "Epoch 655, Loss: 1.123446383896996\n",
      "Epoch 656, Loss: 1.1234454863211687\n",
      "Epoch 657, Loss: 1.1234446518561418\n",
      "Epoch 658, Loss: 1.123443785835715\n",
      "Epoch 659, Loss: 1.1234429583829992\n",
      "Epoch 660, Loss: 1.1234420730787165\n",
      "Epoch 661, Loss: 1.1234412578975452\n",
      "Epoch 662, Loss: 1.1234404059017407\n",
      "Epoch 663, Loss: 1.1234396135105806\n",
      "Epoch 664, Loss: 1.1234386984039755\n",
      "Epoch 665, Loss: 1.1234378849758822\n",
      "Epoch 666, Loss: 1.1234370715477888\n",
      "Epoch 667, Loss: 1.1234361739719616\n",
      "Epoch 668, Loss: 1.1234353500254013\n",
      "Epoch 669, Loss: 1.123434512054219\n",
      "Epoch 670, Loss: 1.123433719663059\n",
      "Epoch 671, Loss: 1.123432878185721\n",
      "Epoch 672, Loss: 1.1234320226837606\n",
      "Epoch 673, Loss: 1.1234311180956222\n",
      "Epoch 674, Loss: 1.1234303502475513\n",
      "Epoch 675, Loss: 1.1234294772148132\n",
      "Epoch 676, Loss: 1.1234286567744087\n",
      "Epoch 677, Loss: 1.123427753939348\n",
      "Epoch 678, Loss: 1.123426963301266\n",
      "Epoch 679, Loss: 1.1234261042931502\n",
      "Epoch 680, Loss: 1.1234253013835234\n",
      "Epoch 681, Loss: 1.1234244248446297\n",
      "Epoch 682, Loss: 1.123423597391914\n",
      "Epoch 683, Loss: 1.1234227489022648\n",
      "Epoch 684, Loss: 1.1234219284618603\n",
      "Epoch 685, Loss: 1.1234210852314443\n",
      "Epoch 686, Loss: 1.1234202630379622\n",
      "Epoch 687, Loss: 1.1234193900052238\n",
      "Epoch 688, Loss: 1.123418555540197\n",
      "Epoch 689, Loss: 1.1234176579643698\n",
      "Epoch 690, Loss: 1.1234168831039877\n",
      "Epoch 691, Loss: 1.1234160416266497\n",
      "Epoch 692, Loss: 1.1234151861246895\n",
      "Epoch 693, Loss: 1.1234143551658182\n",
      "Epoch 694, Loss: 1.1234134786269243\n",
      "Epoch 695, Loss: 1.1234126441618975\n",
      "Epoch 696, Loss: 1.1234118377461153\n",
      "Epoch 697, Loss: 1.1234109506887549\n",
      "Epoch 698, Loss: 1.1234101267421948\n",
      "Epoch 699, Loss: 1.1234092887710123\n",
      "Epoch 700, Loss: 1.1234084472936743\n",
      "Epoch 701, Loss: 1.1234076198409586\n",
      "Epoch 702, Loss: 1.1234067345366758\n",
      "Epoch 703, Loss: 1.1234059263678158\n",
      "Epoch 704, Loss: 1.1234051024212557\n",
      "Epoch 705, Loss: 1.1234042819808512\n",
      "Epoch 706, Loss: 1.12340345102198\n",
      "Epoch 707, Loss: 1.1234026095446419\n",
      "Epoch 708, Loss: 1.1234017715734594\n",
      "Epoch 709, Loss: 1.1234009195776546\n",
      "Epoch 710, Loss: 1.12340008335955\n",
      "Epoch 711, Loss: 1.123399208573734\n",
      "Epoch 712, Loss: 1.123398416182574\n",
      "Epoch 713, Loss: 1.1233975782113916\n",
      "Epoch 714, Loss: 1.1233967051786535\n",
      "Epoch 715, Loss: 1.123395909281338\n",
      "Epoch 716, Loss: 1.1233950572855331\n",
      "Epoch 717, Loss: 1.1233941807466394\n",
      "Epoch 718, Loss: 1.1233933655654682\n",
      "Epoch 719, Loss: 1.1233925311004413\n",
      "Epoch 720, Loss: 1.12339168436387\n",
      "Epoch 721, Loss: 1.1233908288619097\n",
      "Epoch 722, Loss: 1.1233900119276607\n",
      "Epoch 723, Loss: 1.1233892090180342\n",
      "Epoch 724, Loss: 1.123388325466829\n",
      "Epoch 725, Loss: 1.1233874559402466\n",
      "Epoch 726, Loss: 1.1233866390059977\n",
      "Epoch 727, Loss: 1.1233858080471264\n",
      "Epoch 728, Loss: 1.123384970075944\n",
      "Epoch 729, Loss: 1.1233841391170727\n",
      "Epoch 730, Loss: 1.123383311664357\n",
      "Epoch 731, Loss: 1.1233824491500854\n",
      "Epoch 732, Loss: 1.1233816216973698\n",
      "Epoch 733, Loss: 1.1233808082692764\n",
      "Epoch 734, Loss: 1.1233799738042496\n",
      "Epoch 735, Loss: 1.1233790972653557\n",
      "Epoch 736, Loss: 1.1233782733187956\n",
      "Epoch 737, Loss: 1.1233774581376244\n",
      "Epoch 738, Loss: 1.123376628931831\n",
      "Epoch 739, Loss: 1.1233757629114038\n",
      "Epoch 740, Loss: 1.1233749249402214\n",
      "Epoch 741, Loss: 1.123374111512128\n",
      "Epoch 742, Loss: 1.1233732595163233\n",
      "Epoch 743, Loss: 1.1233724601128523\n",
      "Epoch 744, Loss: 1.123371611623203\n",
      "Epoch 745, Loss: 1.123370787676643\n",
      "Epoch 746, Loss: 1.1233699356808382\n",
      "Epoch 747, Loss: 1.1233690906973446\n",
      "Epoch 748, Loss: 1.1233682492200066\n",
      "Epoch 749, Loss: 1.1233674638411577\n",
      "Epoch 750, Loss: 1.1233666398945976\n",
      "Epoch 751, Loss: 1.1233657931580263\n",
      "Epoch 752, Loss: 1.123364970964544\n",
      "Epoch 753, Loss: 1.1233641189687393\n",
      "Epoch 754, Loss: 1.1233632599606234\n",
      "Epoch 755, Loss: 1.1233623974463518\n",
      "Epoch 756, Loss: 1.1233615927836473\n",
      "Epoch 757, Loss: 1.1233607740963207\n",
      "Epoch 758, Loss: 1.1233599080758936\n",
      "Epoch 759, Loss: 1.1233591191908892\n",
      "Epoch 760, Loss: 1.1233582812197067\n",
      "Epoch 761, Loss: 1.123357471297769\n",
      "Epoch 762, Loss: 1.1233566017711865\n",
      "Epoch 763, Loss: 1.1233557673061596\n",
      "Epoch 764, Loss: 1.1233549573842216\n",
      "Epoch 765, Loss: 1.1233541229191948\n",
      "Epoch 766, Loss: 1.1233533340341904\n",
      "Epoch 767, Loss: 1.1233524925568525\n",
      "Epoch 768, Loss: 1.123351679128759\n",
      "Epoch 769, Loss: 1.1233508096021765\n",
      "Epoch 770, Loss: 1.1233499576063717\n",
      "Epoch 771, Loss: 1.123349179239834\n",
      "Epoch 772, Loss: 1.123348362305585\n",
      "Epoch 773, Loss: 1.1233475348528694\n",
      "Epoch 774, Loss: 1.1233467249309315\n",
      "Epoch 775, Loss: 1.1233458624166601\n",
      "Epoch 776, Loss: 1.1233450261985554\n",
      "Epoch 777, Loss: 1.1233442373135512\n",
      "Epoch 778, Loss: 1.123343388823902\n",
      "Epoch 779, Loss: 1.1233425578650307\n",
      "Epoch 780, Loss: 1.123341777745415\n",
      "Epoch 781, Loss: 1.1233409292557661\n",
      "Epoch 782, Loss: 1.1233401193338282\n",
      "Epoch 783, Loss: 1.1233392988934237\n",
      "Epoch 784, Loss: 1.1233384609222412\n",
      "Epoch 785, Loss: 1.1233376194449032\n",
      "Epoch 786, Loss: 1.1233368060168099\n",
      "Epoch 787, Loss: 1.1233359925887163\n",
      "Epoch 788, Loss: 1.1233351493583006\n",
      "Epoch 789, Loss: 1.1233343113871181\n",
      "Epoch 790, Loss: 1.123333520749036\n",
      "Epoch 791, Loss: 1.1233326687532312\n",
      "Epoch 792, Loss: 1.1233318448066711\n",
      "Epoch 793, Loss: 1.1233310454032\n",
      "Epoch 794, Loss: 1.123330228468951\n",
      "Epoch 795, Loss: 1.1233294010162354\n",
      "Epoch 796, Loss: 1.1233285665512085\n",
      "Epoch 797, Loss: 1.1233277566292708\n",
      "Epoch 798, Loss: 1.1233269116457771\n",
      "Epoch 799, Loss: 1.123326094711528\n",
      "Epoch 800, Loss: 1.1233253023203682\n",
      "Epoch 801, Loss: 1.123324502916897\n",
      "Epoch 802, Loss: 1.1233236509210922\n",
      "Epoch 803, Loss: 1.1233228339868433\n",
      "Epoch 804, Loss: 1.1233220135464388\n",
      "Epoch 805, Loss: 1.1233212071306564\n",
      "Epoch 806, Loss: 1.1233204077271854\n",
      "Epoch 807, Loss: 1.1233195942990921\n",
      "Epoch 808, Loss: 1.1233187808709986\n",
      "Epoch 809, Loss: 1.123317920109805\n",
      "Epoch 810, Loss: 1.1233171399901896\n",
      "Epoch 811, Loss: 1.1233162985128515\n",
      "Epoch 812, Loss: 1.1233154991093803\n",
      "Epoch 813, Loss: 1.1233146751628202\n",
      "Epoch 814, Loss: 1.1233138582285713\n",
      "Epoch 815, Loss: 1.1233130325289333\n",
      "Epoch 816, Loss: 1.12331220332314\n",
      "Epoch 817, Loss: 1.12331141093198\n",
      "Epoch 818, Loss: 1.123310569454642\n",
      "Epoch 819, Loss: 1.1233097665450151\n",
      "Epoch 820, Loss: 1.123308942598455\n",
      "Epoch 821, Loss: 1.1233081572196062\n",
      "Epoch 822, Loss: 1.1233073087299572\n",
      "Epoch 823, Loss: 1.1233064549810745\n",
      "Epoch 824, Loss: 1.1233056608368368\n",
      "Epoch 825, Loss: 1.1233048403964323\n",
      "Epoch 826, Loss: 1.1233040322275722\n",
      "Epoch 827, Loss: 1.123303217046401\n",
      "Epoch 828, Loss: 1.1233023966059965\n",
      "Epoch 829, Loss: 1.123301551622503\n",
      "Epoch 830, Loss: 1.1233007802682764\n",
      "Epoch 831, Loss: 1.1232999107416939\n",
      "Epoch 832, Loss: 1.1232990885482115\n",
      "Epoch 833, Loss: 1.1232983084285961\n",
      "Epoch 834, Loss: 1.1232975020128138\n",
      "Epoch 835, Loss: 1.123296667547787\n",
      "Epoch 836, Loss: 1.1232958716504715\n",
      "Epoch 837, Loss: 1.1232950441977556\n",
      "Epoch 838, Loss: 1.12329421674504\n",
      "Epoch 839, Loss: 1.1232934243538801\n",
      "Epoch 840, Loss: 1.1232925618396086\n",
      "Epoch 841, Loss: 1.1232917887323044\n",
      "Epoch 842, Loss: 1.123290931477266\n",
      "Epoch 843, Loss: 1.123290140839184\n",
      "Epoch 844, Loss: 1.1232893361764795\n",
      "Epoch 845, Loss: 1.1232885017114527\n",
      "Epoch 846, Loss: 1.123287691789515\n",
      "Epoch 847, Loss: 1.1232868958921993\n",
      "Epoch 848, Loss: 1.1232861175256617\n",
      "Epoch 849, Loss: 1.1232852550113903\n",
      "Epoch 850, Loss: 1.1232844696325415\n",
      "Epoch 851, Loss: 1.123283614130581\n",
      "Epoch 852, Loss: 1.123282823492499\n",
      "Epoch 853, Loss: 1.1232820118174833\n",
      "Epoch 854, Loss: 1.1232812194263233\n",
      "Epoch 855, Loss: 1.1232804042451523\n",
      "Epoch 856, Loss: 1.1232795750393587\n",
      "Epoch 857, Loss: 1.1232787405743319\n",
      "Epoch 858, Loss: 1.1232779481831718\n",
      "Epoch 859, Loss: 1.123277122483534\n",
      "Epoch 860, Loss: 1.1232763160677517\n",
      "Epoch 861, Loss: 1.1232755008865805\n",
      "Epoch 862, Loss: 1.1232746874584871\n",
      "Epoch 863, Loss: 1.1232738600057715\n",
      "Epoch 864, Loss: 1.1232730676146114\n",
      "Epoch 865, Loss: 1.1232722559395958\n",
      "Epoch 866, Loss: 1.123271430239958\n",
      "Epoch 867, Loss: 1.1232706308364868\n",
      "Epoch 868, Loss: 1.1232697981245376\n",
      "Epoch 869, Loss: 1.1232689969679888\n",
      "Epoch 870, Loss: 1.1232682080829846\n",
      "Epoch 871, Loss: 1.123267363099491\n",
      "Epoch 872, Loss: 1.1232665812267977\n",
      "Epoch 873, Loss: 1.1232657748110153\n",
      "Epoch 874, Loss: 1.1232649333336775\n",
      "Epoch 875, Loss: 1.1232640988686506\n",
      "Epoch 876, Loss: 1.123263334526735\n",
      "Epoch 877, Loss: 1.1232625000617082\n",
      "Epoch 878, Loss: 1.1232616813743816\n",
      "Epoch 879, Loss: 1.123260852168588\n",
      "Epoch 880, Loss: 1.1232600492589615\n",
      "Epoch 881, Loss: 1.1232592884232016\n",
      "Epoch 882, Loss: 1.1232584469458635\n",
      "Epoch 883, Loss: 1.1232576335177702\n",
      "Epoch 884, Loss: 1.1232567955465877\n",
      "Epoch 885, Loss: 1.1232559961431168\n",
      "Epoch 886, Loss: 1.1232552493319792\n",
      "Epoch 887, Loss: 1.1232543903238632\n",
      "Epoch 888, Loss: 1.1232535768957699\n",
      "Epoch 889, Loss: 1.1232527950230766\n",
      "Epoch 890, Loss: 1.1232519465334274\n",
      "Epoch 891, Loss: 1.123251126093023\n",
      "Epoch 892, Loss: 1.1232502951341516\n",
      "Epoch 893, Loss: 1.123249467681436\n",
      "Epoch 894, Loss: 1.1232487138579874\n",
      "Epoch 895, Loss: 1.1232478688744938\n",
      "Epoch 896, Loss: 1.123247065964867\n",
      "Epoch 897, Loss: 1.1232462700675516\n",
      "Epoch 898, Loss: 1.1232454671579248\n",
      "Epoch 899, Loss: 1.1232446537298315\n",
      "Epoch 900, Loss: 1.1232438122524935\n",
      "Epoch 901, Loss: 1.123243005836711\n",
      "Epoch 902, Loss: 1.1232422414947958\n",
      "Epoch 903, Loss: 1.1232414017705357\n",
      "Epoch 904, Loss: 1.123240607626298\n",
      "Epoch 905, Loss: 1.1232397854328156\n",
      "Epoch 906, Loss: 1.1232389947947334\n",
      "Epoch 907, Loss: 1.1232381918851067\n",
      "Epoch 908, Loss: 1.123237346901613\n",
      "Epoch 909, Loss: 1.1232365930781645\n",
      "Epoch 910, Loss: 1.1232357586131376\n",
      "Epoch 911, Loss: 1.1232349662219776\n",
      "Epoch 912, Loss: 1.1232341861023623\n",
      "Epoch 913, Loss: 1.1232333358596354\n",
      "Epoch 914, Loss: 1.1232325329500086\n",
      "Epoch 915, Loss: 1.1232317160157597\n",
      "Epoch 916, Loss: 1.1232309306369108\n",
      "Epoch 917, Loss: 1.123230113702662\n",
      "Epoch 918, Loss: 1.1232293388422798\n",
      "Epoch 919, Loss: 1.1232284938587862\n",
      "Epoch 920, Loss: 1.1232276804306929\n",
      "Epoch 921, Loss: 1.123226895051844\n",
      "Epoch 922, Loss: 1.123226078117595\n",
      "Epoch 923, Loss: 1.1232252576771904\n",
      "Epoch 924, Loss: 1.1232244880760418\n",
      "Epoch 925, Loss: 1.1232236623764038\n",
      "Epoch 926, Loss: 1.1232228559606217\n",
      "Epoch 927, Loss: 1.1232220565571505\n",
      "Epoch 928, Loss: 1.123221269425224\n",
      "Epoch 929, Loss: 1.1232204822932972\n",
      "Epoch 930, Loss: 1.1232196793836706\n",
      "Epoch 931, Loss: 1.1232188764740438\n",
      "Epoch 932, Loss: 1.1232180770705729\n",
      "Epoch 933, Loss: 1.1232172951978796\n",
      "Epoch 934, Loss: 1.1232164887820972\n",
      "Epoch 935, Loss: 1.1232156648355371\n",
      "Epoch 936, Loss: 1.1232148601728327\n",
      "Epoch 937, Loss: 1.1232140414855059\n",
      "Epoch 938, Loss: 1.123213264872046\n",
      "Epoch 939, Loss: 1.1232124426785637\n",
      "Epoch 940, Loss: 1.1232116345097036\n",
      "Epoch 941, Loss: 1.1232108438716215\n",
      "Epoch 942, Loss: 1.1232100514804615\n",
      "Epoch 943, Loss: 1.1232092520769905\n",
      "Epoch 944, Loss: 1.1232084105996525\n",
      "Epoch 945, Loss: 1.1232076111961813\n",
      "Epoch 946, Loss: 1.1232068047803991\n",
      "Epoch 947, Loss: 1.1232060614754171\n",
      "Epoch 948, Loss: 1.1232052620719462\n",
      "Epoch 949, Loss: 1.1232044591623194\n",
      "Epoch 950, Loss: 1.1232036772896261\n",
      "Epoch 951, Loss: 1.1232028323061325\n",
      "Epoch 952, Loss: 1.123202078482684\n",
      "Epoch 953, Loss: 1.1232012580422794\n",
      "Epoch 954, Loss: 1.1232004726634306\n",
      "Epoch 955, Loss: 1.123199676766115\n",
      "Epoch 956, Loss: 1.1231989001526552\n",
      "Epoch 957, Loss: 1.1231981375638176\n",
      "Epoch 958, Loss: 1.1231972995926351\n",
      "Epoch 959, Loss: 1.1231965317445642\n",
      "Epoch 960, Loss: 1.123195700785693\n",
      "Epoch 961, Loss: 1.1231948873575996\n",
      "Epoch 962, Loss: 1.1231940984725952\n",
      "Epoch 963, Loss: 1.1231933201060575\n",
      "Epoch 964, Loss: 1.1231925101841198\n",
      "Epoch 965, Loss: 1.123191742336049\n",
      "Epoch 966, Loss: 1.123190907871022\n",
      "Epoch 967, Loss: 1.1231901224921732\n",
      "Epoch 968, Loss: 1.123189291533302\n",
      "Epoch 969, Loss: 1.1231885289444643\n",
      "Epoch 970, Loss: 1.123187706750982\n",
      "Epoch 971, Loss: 1.123186938902911\n",
      "Epoch 972, Loss: 1.1231861430055954\n",
      "Epoch 973, Loss: 1.1231853611329023\n",
      "Epoch 974, Loss: 1.123184603803298\n",
      "Epoch 975, Loss: 1.1231837693382711\n",
      "Epoch 976, Loss: 1.1231829734409557\n",
      "Epoch 977, Loss: 1.1231822266298181\n",
      "Epoch 978, Loss: 1.1231814307325028\n",
      "Epoch 979, Loss: 1.1231806383413427\n",
      "Epoch 980, Loss: 1.123179875752505\n",
      "Epoch 981, Loss: 1.123179085114423\n",
      "Epoch 982, Loss: 1.1231782716863297\n",
      "Epoch 983, Loss: 1.1231774880605585\n",
      "Epoch 984, Loss: 1.1231766728793873\n",
      "Epoch 985, Loss: 1.1231758980190052\n",
      "Epoch 986, Loss: 1.1231751038747675\n",
      "Epoch 987, Loss: 1.1231743097305298\n",
      "Epoch 988, Loss: 1.12317354889477\n",
      "Epoch 989, Loss: 1.1231727004051208\n",
      "Epoch 990, Loss: 1.1231719080139608\n",
      "Epoch 991, Loss: 1.1231711261412676\n",
      "Epoch 992, Loss: 1.1231703267377966\n",
      "Epoch 993, Loss: 1.123169513309703\n",
      "Epoch 994, Loss: 1.1231687875354992\n",
      "Epoch 995, Loss: 1.1231679478112389\n",
      "Epoch 996, Loss: 1.123167164185468\n",
      "Epoch 997, Loss: 1.1231663823127747\n",
      "Epoch 998, Loss: 1.1231655899216146\n",
      "Epoch 999, Loss: 1.1231648045427658\n",
      "Epoch 1000, Loss: 1.1231640349416172\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_data, epochs=1000, learning_rate=0.01):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for target, context in train_data:\n",
    "            model.zero_grad()\n",
    "            target_tensor = torch.LongTensor([target])\n",
    "            context_tensor = torch.LongTensor([context])\n",
    "\n",
    "            # Forward pass\n",
    "            target_embedding = model(target_tensor)\n",
    "            context_embedding = model(context_tensor)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = loss_function(context_embedding, target_tensor)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch {epoch + 1}, Loss: {total_loss / len(train_data)}')\n",
    "\n",
    "# Train the model\n",
    "train(model, train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'machine': [ 8.126439    8.129772    0.7252991   8.133117    0.25418976  0.49002394\n",
      " -1.0997905  -0.63741374 -0.6465995  -0.15473226  0.85699666 -1.4416742\n",
      " -0.9427264  -0.5531723   0.46146333  0.17594765  0.38562477 -1.7902838\n",
      " -1.5103159  -0.26706764 -0.08852424 -0.86723286 -0.3413107  -1.2261378\n",
      "  0.83645266  0.6808256   0.42835283  0.32362387 -0.03676874  0.78955114\n",
      " -0.29805484  0.5212648   0.25227913  1.1987727  -0.6976225  -0.7375602\n",
      " -0.5263302  -1.4002227  -1.3707819  -0.6416115  -0.24766174  0.7462435\n",
      "  0.4246255   0.16425882 -1.1846856   0.7377627  -1.9570324   0.05758411\n",
      " -1.3206551   0.16330306  0.11491979  0.8962373  -0.50969404  0.02866176\n",
      " -1.9531775  -1.289838    1.1487489  -0.36546615 -0.19983907 -0.2504535\n",
      " -0.11959472  0.51396155 -0.8894359  -0.5215879  -0.23827577  0.01499586\n",
      "  0.97730565 -1.7139233  -0.36816004 -1.0194905   0.15408482  0.26004624\n",
      "  0.23473375 -0.45649248 -0.93150574 -0.20459637  0.56511635 -0.21108636\n",
      " -0.06801974  0.47038355 -1.3199807  -0.28548458  0.19476922  0.6774658\n",
      " -0.21264726 -0.17859915 -1.9573945  -0.5763514  -1.1879995  -0.67721826\n",
      " -1.8084766   0.62452894  0.8831038  -0.11284585 -0.9644711  -0.4561059\n",
      " -0.5341579  -0.05960855 -0.71516585 -2.4108458 ]\n"
     ]
    }
   ],
   "source": [
    "word_vectors = model.embeddings.weight.data.numpy()\n",
    "\n",
    "# Example: Get vector for a specific word\n",
    "word_index = word2dix['machine']\n",
    "print(f\"Vector for 'machine': {word_vectors[word_index]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
